{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing and Pipelines\n",
    "https://docs.python.org/3/library/multiprocessing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary sequential execution example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from os import getpid\n",
    "\n",
    "def square(x):\n",
    "    \"\"\"Dummy method representing a complex computation.\"\"\"\n",
    "    print(\"x: {} pid: {}\".format(x, getpid()))\n",
    "    # simulate a long calculation\n",
    "    time.sleep(1)\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0 pid: 21073\n",
      "x: 1 pid: 21073\n",
      "x: 2 pid: 21073\n",
      "x: 3 pid: 21073\n",
      "x: 4 pid: 21073\n",
      "execution time: 5.0085179805755615\n",
      "[0, 1, 4, 9, 16]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "start = time.time()\n",
    "results = [square(i) for i in range(5)]\n",
    "end = time.time()\n",
    "\n",
    "print(\"execution time: {}\".format(end - start))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Pools\n",
    "https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit tasks to a pool which then coordinates the execution.\n",
    "\n",
    "There are 3 main uses for this class:\n",
    "* apply_async - doing everything by hand\n",
    "* map - parallel map equivalent\n",
    "* starmap - like map, but accepts multiple arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using apply_async\n",
    "\n",
    "(doing everythin by hand):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time: 1.1349742412567139\n",
      "[16, 9, 0, 4, 1]\n",
      "x: 0 pid: 14875\n",
      "x: 2 pid: 14877\n",
      "x: 4 pid: 14879\n",
      "x: 3 pid: 14878\n",
      "x: 1 pid: 14876\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "results = []\n",
    "def collect_results(result):\n",
    "    results.append(result)\n",
    "\n",
    "start = time.time()\n",
    "pool = Pool()\n",
    "for i in range(5):\n",
    "    pool.apply_async(square, args=(i, ), callback=collect_results)\n",
    "pool.close() # prevents submitting of additional tasks, start execution\n",
    "pool.join() # wait for all tasks to finish\n",
    "end = time.time()\n",
    "\n",
    "print(\"execution time: {}\".format(end - start))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "* The results are not sorted!\n",
    "* The calls of Pool.close() and Pool.join() are neccessary\n",
    "    * close() prevents submitting of additional tasks and starts the execution of the tasks\n",
    "    * join() waits for all submitted tasks to finish\n",
    "\n",
    "### Using map\n",
    "\n",
    "Map is a builtin funciton which returns an iterable with a given function applied to all elements of a given iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x7f6c60fb49b0>\n",
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "def double_it(x):\n",
    "    return x * 2\n",
    "\n",
    "mapped = map(double_it, range(10))\n",
    "\n",
    "print(mapped)\n",
    "print(list(mapped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also a Pool.map() function which resembles it's behaviour, but distributes the computation across multiple processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time: 1.1291108131408691\n",
      "[0, 1, 4, 9, 16]\n",
      "id: 14828\n",
      "id: 14829\n",
      "id: 14826\n",
      "id: 14825\n",
      "id: 14827\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "with Pool() as pool:\n",
    "    results = pool.map(square, range(5))\n",
    "end = time.time()\n",
    "\n",
    "print(\"execution time: {}\".format(end - start))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to consider when running code in parallel\n",
    "\n",
    "* Resources (RAM, HDD-throughput) must be available for x parallel runs\n",
    "* Parallel tasks should be equal in \"size\"\n",
    "* Printing to stdout might not be readable\n",
    "* Access to variables shared amongh threads must be synchronized with semaphores (https://docs.python.org/3.6/library/multiprocessing.html#multiprocessing.Semaphore)\n",
    "\n",
    "\n",
    "A fork of multiprocessing is available at:\n",
    "https://github.com/uqfoundation/multiprocess\n",
    "\n",
    "#### Dask\n",
    "http://dask.pydata.org/en/latest/install.html\n",
    "\n",
    "A dataframe composed by multiple pandas DataFrames. Tasks are distributed across multiple cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Until now:\n",
    "* Tasks were done in separate steps like:\n",
    "    * Read all csv files\n",
    "    * Create all dataframes\n",
    "    \n",
    "Pipelines let you join subsequent tasks per dataset together. E.g. when analyzing text documents the different tasks could be:\n",
    "* remove stop words\n",
    "* determine stem words\n",
    "* remove dublicates\n",
    "As soon as the task \"remove stop words\" for document a is finished task \"determine stem words\" for document a is started. Same for document b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Task\n",
    "\n",
    "Read content from a web source n-times.\n",
    "Possible sources could be:\n",
    "* generate x bytes with http://httpbin.org (https://httpbin.org/bytes/:n)\n",
    "* use \"http://www.google.com\"\n",
    "\n",
    "Compare the execution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serial: 5.78494930267334\n",
      "parallel: 1.2398285865783691\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from urllib.request import urlopen\n",
    "\n",
    "ITERATIONS = 10\n",
    "BYTES_TO_READ = 1024\n",
    "URL_TO_READ = \"https://httpbin.org/bytes/{}\".format(BYTES_TO_READ)\n",
    "\n",
    "def read_page(url=URL_TO_READ):\n",
    "    with urlopen(url) as f:\n",
    "        f.read()\n",
    "\n",
    "start = time.time()\n",
    "for i in range(ITERATIONS):\n",
    "    read_page(\"http://www.google.com\")\n",
    "end = time.time()\n",
    "print(\"serial: {}\".format(end - start))\n",
    "\n",
    "start = time.time()\n",
    "pool = Pool()\n",
    "for i in range(ITERATIONS):\n",
    "    pool.apply_async(read_page, (\"http://www.google.com\", ))\n",
    "pool.close()\n",
    "pool.join()\n",
    "end = time.time()\n",
    "print(\"parallel: {}\".format(end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
